{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 22:02:00.997132: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-21 22:02:01.301773: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "import tensorflow as tf\n",
    "import glob, os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Optional TF setting\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"dataset/training_data\"\n",
    "txt_files = glob.glob(data_folder + \"/*.txt\")\n",
    "\n",
    "data = []\n",
    "for file in txt_files:\n",
    "    temp = {}\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line[0].isdigit():\n",
    "                temp['id'] = line.split(\" \")[0].strip()\n",
    "            if line.startswith(\"#Age:\"):\n",
    "                temp['age'] = line.split(\" \")[-1].strip()\n",
    "            if line.startswith(\"#Sex:\"):\n",
    "                temp['sex'] = line.split(\" \")[-1].strip()\n",
    "            if line.startswith(\"#Height:\"):\n",
    "                temp['height'] = float(line.split(\" \")[-1].strip())\n",
    "            if line.startswith(\"#Weight:\"):\n",
    "                temp['weight'] = float(line.split(\" \")[-1].strip())\n",
    "            if line.startswith(\"#Pregnancy\"):\n",
    "                temp['preg'] = line.split(\" \")[-1].strip() == \"True\"\n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>preg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84743</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>107.0</td>\n",
       "      <td>18.600</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84978</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>102.0</td>\n",
       "      <td>18.400</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50751</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>116.0</td>\n",
       "      <td>19.100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84784</td>\n",
       "      <td>Neonate</td>\n",
       "      <td>Female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.816</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68888</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>68204</td>\n",
       "      <td>Adolescent</td>\n",
       "      <td>Male</td>\n",
       "      <td>165.0</td>\n",
       "      <td>48.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>49808</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>121.0</td>\n",
       "      <td>24.200</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>68436</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>133.0</td>\n",
       "      <td>24.900</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>50231</td>\n",
       "      <td>Adolescent</td>\n",
       "      <td>Male</td>\n",
       "      <td>143.0</td>\n",
       "      <td>40.400</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>49598</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>83.0</td>\n",
       "      <td>13.800</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         age     sex  height  weight   preg\n",
       "0    84743       Child    Male   107.0  18.600  False\n",
       "1    84978       Child    Male   102.0  18.400  False\n",
       "2    50751       Child  Female   116.0  19.100  False\n",
       "3    84784     Neonate  Female    47.0   2.816  False\n",
       "4    68888       Child    Male     NaN     NaN  False\n",
       "..     ...         ...     ...     ...     ...    ...\n",
       "937  68204  Adolescent    Male   165.0  48.000  False\n",
       "938  49808       Child    Male   121.0  24.200  False\n",
       "939  68436       Child  Female   133.0  24.900  False\n",
       "940  50231  Adolescent    Male   143.0  40.400  False\n",
       "941  49598       Child    Male    83.0  13.800  False\n",
       "\n",
       "[942 rows x 6 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data)\n",
    "df = df.replace(\"nan\", np.nan)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>preg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>50164</td>\n",
       "      <td>Adolescent</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         age     sex  height  weight   preg\n",
       "634  50164  Adolescent  Female     NaN     NaN  False"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['id'] == '50164']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    837.000000\n",
       "mean      23.632756\n",
       "std       15.453337\n",
       "min        2.300000\n",
       "25%       12.500000\n",
       "50%       20.400000\n",
       "75%       31.200000\n",
       "max      110.800000\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weight'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special type: Female, Adult null values --> Female, Adolescent mean values\n",
    "adole_height = df[(df[\"sex\"] == \"Female\") & (df[\"age\"] == \"Adolescent\")]['height'].mean()\n",
    "adole_weight = df[(df[\"sex\"] == \"Female\") & (df[\"age\"] == \"Adolescent\")]['weight'].mean()\n",
    "df.loc[(df[\"sex\"] == \"Female\") & (df[\"age\"] == \"Adolescent\") & (df[\"height\"].isna()), \"height\"] = adole_height.round(1)\n",
    "df.loc[(df[\"sex\"] == \"Female\") & (df[\"age\"] == \"Adolescent\") & (df[\"weight\"].isna()), \"weight\"] = adole_weight.round(1)\n",
    "\n",
    "df.loc[df[\"preg\"] == True, \"age\"] = \"Adult\"\n",
    "df.loc[(df[\"sex\"] == \"Female\") & (df[\"age\"] == \"Adult\") & (df[\"height\"].isna()), \"height\"] = adole_height.round(1)\n",
    "df.loc[(df[\"sex\"] == \"Female\") & (df[\"age\"] == \"Adult\") & (df[\"weight\"].isna()), \"weight\"] = adole_weight.round(1)\n",
    "\n",
    "# Male, Infant null values --> mean values\n",
    "infant_height = df[(df[\"sex\"] == \"Male\") & (df[\"age\"] == \"Infant\")]['height'].mean()\n",
    "infant_weight = df[(df[\"sex\"] == \"Male\") & (df[\"age\"] == \"Infant\")]['weight'].mean()\n",
    "df.loc[(df[\"sex\"] == \"Male\") & (df[\"height\"].isna()), \"height\"] = infant_height.round(1)\n",
    "df.loc[(df[\"sex\"] == \"Male\") & (df[\"weight\"].isna()), \"weight\"] = infant_weight.round(1)\n",
    "\n",
    "# General Type: just mean values\n",
    "typeset = [\n",
    "    (\"Male\", \"Infant\"), (\"Female\", \"Infant\"),\n",
    "    (\"Male\", \"Child\"), (\"Female\", \"Child\"), \n",
    "    (\"Male\", \"Adolescent\"),\n",
    "]\n",
    "\n",
    "for t in typeset:\n",
    "    t_height = df[(df[\"sex\"] == t[0]) & (df[\"age\"] == t[1])]['height'].mean()\n",
    "    t_weight = df[(df[\"sex\"] == t[0]) & (df[\"age\"] == t[1])]['weight'].mean()\n",
    "    df.loc[(df[\"sex\"] == t[0]) & (df[\"age\"] == t[1]) & (df[\"height\"].isna()), \"height\"] = t_height.round(1)\n",
    "    df.loc[(df[\"sex\"] == t[0]) & (df[\"age\"] == t[1]) & (df[\"weight\"].isna()), \"weight\"] = t_weight.round(1)\n",
    "\n",
    "# No age Type: Manual Setup\n",
    "df.loc[(df[\"id\"] == \"50819\"), \"age\"] = \"Child\"\n",
    "df.loc[(df[\"id\"] == \"85113\"), \"age\"] = \"Child\"\n",
    "df.loc[(df[\"id\"] == \"50734\"), \"age\"] = \"Adult\"\n",
    "df.loc[(df[\"id\"] == \"85219\"), \"age\"] = \"Child\"\n",
    "\n",
    "# Error on base data: Manual Setup\n",
    "df.loc[(df[\"id\"] == \"50797\"), \"age\"] = \"Adolescent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>preg</th>\n",
       "      <th>age_0</th>\n",
       "      <th>age_1</th>\n",
       "      <th>age_2</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84743</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84978</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.122667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.127333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84784</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.018773</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68888</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3165</td>\n",
       "      <td>0.052667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>68204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>49808</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>0.161333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>68436</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6650</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>50231</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7150</td>\n",
       "      <td>0.269333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>49598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  sex  height    weight  preg  age_0  age_1  age_2  age_3  age_4\n",
       "0    84743    0  0.5350  0.124000     0      0      0      1      0      0\n",
       "1    84978    0  0.5100  0.122667     0      0      0      1      0      0\n",
       "2    50751    1  0.5800  0.127333     0      0      0      1      0      0\n",
       "3    84784    1  0.2350  0.018773     0      1      0      0      0      0\n",
       "4    68888    0  0.3165  0.052667     0      0      0      1      0      0\n",
       "..     ...  ...     ...       ...   ...    ...    ...    ...    ...    ...\n",
       "937  68204    0  0.8250  0.320000     0      0      0      0      1      0\n",
       "938  49808    0  0.6050  0.161333     0      0      0      1      0      0\n",
       "939  68436    1  0.6650  0.166000     0      0      0      1      0      0\n",
       "940  50231    0  0.7150  0.269333     0      0      0      0      1      0\n",
       "941  49598    0  0.4150  0.092000     0      0      0      1      0      0\n",
       "\n",
       "[942 rows x 10 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#['Infant', 'Child', 'Adolescent', 'Adult', 'Neonate']\n",
    "#['Male', 'Female']\n",
    "\n",
    "age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Adult']\n",
    "sex_classes = ['Male', 'Female']\n",
    "\n",
    "df['age'] = df['age'].apply(lambda x: age_classes.index(x))\n",
    "df = pd.get_dummies(df, columns = ['age'])\n",
    "\n",
    "#df['height'] = df['height'] / df['height'].max()\n",
    "#df['weight'] = df['weight'] / df['weight'].max()\n",
    "df['height'] = df['height'] / 200\n",
    "df['weight'] = df['weight'] / 150\n",
    "df['sex'] = df['sex'].apply(lambda x: sex_classes.index(x))\n",
    "df['preg'] = df['preg'].apply(lambda x: 1 if x == True else 0)\n",
    "\n",
    "demo_df = df\n",
    "demo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "from scipy.io import wavfile\n",
    "\n",
    "class Preprocessor():\n",
    "    def __init__(self, data_folder, output_folder, classes = [], trimming=True):\n",
    "        self.data_folder = data_folder\n",
    "        self.output_folder = output_folder\n",
    "        self.list_ids = []\n",
    "        self.max_length = 0\n",
    "        self.classes = classes\n",
    "        self.labels = {}\n",
    "        self.trimming = trimming\n",
    "        \n",
    "        shutil.rmtree(self.output_folder, ignore_errors=False)\n",
    "        os.makedirs(self.output_folder)\n",
    "        \n",
    "    def __process_tsv(self, tsv_file, murmur):        \n",
    "        root, ext = os.path.splitext(tsv_file)\n",
    "        pid = root.split(\"/\")[-1]\n",
    "        frequency, recording = wavfile.read(root + '.wav')\n",
    "        \n",
    "        if self.trimming:\n",
    "            tsv_data = []\n",
    "            with open(tsv_file, \"r\") as f:\n",
    "                for line in f:\n",
    "                    tsv_data.append(line.strip().split('\\t'))\n",
    "\n",
    "            tsv_starts = None\n",
    "            tsv_ends = None\n",
    "\n",
    "            for i in range(len(tsv_data)):\n",
    "                if not tsv_data[i][2] == 0:\n",
    "                    tsv_start = float(tsv_data[i][0])\n",
    "                    break\n",
    "            for i in range(1, len(tsv_data)+1):\n",
    "                if not tsv_data[-i][2] == 0:\n",
    "                    tsv_ends = float(tsv_data[-i][1])\n",
    "                    break\n",
    "\n",
    "            frame_starts = int(frequency * tsv_start)\n",
    "            frame_ends = int(frequency * tsv_ends)\n",
    "            output_record = recording[frame_starts:frame_ends]\n",
    "            output_length = len(output_record)\n",
    "        else:\n",
    "            output_length = len(recording)\n",
    "\n",
    "        if self.max_length < output_length:\n",
    "            self.max_length = output_length\n",
    "            \n",
    "        if murmur not in self.classes:\n",
    "            self.classes.append(murmur)\n",
    "            \n",
    "        self.list_ids.append(pid)\n",
    "        self.labels[pid.split(\"_\")[0]] = self.classes.index(murmur)\n",
    "        \n",
    "        output_npy = self.output_folder + \"/\" + pid + \".npy\"\n",
    "        np.save(output_npy, output_record)\n",
    "        \n",
    "    def __process_txt(self, txt_file):\n",
    "        root, ext = os.path.splitext(txt_file)\n",
    "        dirs = \"/\".join(root.split(\"/\")[:-1])\n",
    "        pid = root.split(\"/\")[-1]\n",
    "        \n",
    "        tsv_files = []\n",
    "        pos = ['AV', 'MV', 'TV', 'PV', 'Phc']\n",
    "        murmur = None\n",
    "        \n",
    "        with open(txt_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                splitted = line.strip().split(\" \")\n",
    "                if splitted[0] in pos:\n",
    "                    for i in splitted[1:]:\n",
    "                        if i.endswith(\".tsv\"):\n",
    "                            tsv_files.append(dirs + \"/\" + i)\n",
    "                elif splitted[0].startswith(\"#Murmur:\"):\n",
    "                    murmur = splitted[1]\n",
    "        \n",
    "        for file in tsv_files:\n",
    "            self.__process_tsv(file, murmur)\n",
    "                    \n",
    "    def process(self):\n",
    "        for f in glob.glob(self.data_folder + \"/*.txt\"):\n",
    "            self.__process_txt(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"dataset/training_data\"\n",
    "output_folder = \"trimmed_npy\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "classes = ['Present', 'Unknown', 'Absent',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = Preprocessor(data_folder, output_folder, classes)\n",
    "pp.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplitter():\n",
    "    def __init__(self, data_folder, output_folder, list_ids, labels, window_size, classes=[]):\n",
    "        self.data_folder = data_folder\n",
    "        self.output_folder = output_folder\n",
    "        self.window_size = window_size\n",
    "        self.classes = classes\n",
    "        self.list_ids = list_ids\n",
    "        self.labels = labels\n",
    "        self.output_list_ids = []\n",
    "        self.output_labels = {}\n",
    "        \n",
    "        shutil.rmtree(self.output_folder, ignore_errors=False)\n",
    "        os.makedirs(self.output_folder)\n",
    "        \n",
    "    def __process_npy(self, npy_file):\n",
    "        root, ext = os.path.splitext(npy_file)\n",
    "        pid = root.split(\"/\")[-1]\n",
    "        data = np.load(npy_file)\n",
    "        \n",
    "        for i in range(data.shape[0]//(self.window_size//2)):\n",
    "            splitted = data[i*(self.window_size//2):(i+2)*(self.window_size//2)]\n",
    "            output_npy = self.output_folder + \"/\" + pid + \"_\" + str(i) + \".npy\"\n",
    "            np.save(output_npy, splitted)\n",
    "            self.output_list_ids.append(pid + \"_\" + str(i))\n",
    "     \n",
    "    def process(self):\n",
    "        for f in glob.glob(self.data_folder + \"/*.npy\"):\n",
    "            self.__process_npy(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"trimmed_npy\"\n",
    "output_folder = \"splitted_npy\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "window_size = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSplitter(data_folder, output_folder, pp.list_ids, pp.labels, window_size, classes)\n",
    "ds.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data_folder, list_IDs, demo_df, labels, batch_size, dim, n_classes, shuffle=True):\n",
    "        self.data_folder = data_folder\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.demo_df = demo_df\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        X = np.empty((len(list_IDs_temp), *self.dim))\n",
    "        d = np.empty((len(list_IDs_temp),9))\n",
    "        y = np.empty(len(list_IDs_temp), dtype=int)\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            #frequency, recording = sp.io.wavfile.read(self.data_folder + \"/\" + ID + '.wav')\n",
    "            X[i,] = np.zeros(dim)\n",
    "            signal = np.load(data_folder + \"/\" + ID + \".npy\").reshape(-1, 1)\n",
    "            signal = signal / np.max(abs(signal))\n",
    "            #offset = random.randrange(0, signal.shape[0]-dim[0])\n",
    "            #X[i,:signal.shape[0],:signal.shape[1]] = signal[offset:offset+dim[0],:]\n",
    "            X[i,:signal.shape[0],:signal.shape[1]] = signal\n",
    "            y[i] = self.labels[ID.split(\"_\")[0]]\n",
    "\n",
    "            d[i,:] = np.array(demo_df.loc[demo_df['id'] == ID.split(\"_\")[0]].values[0][1:]).astype(float).reshape(-1)\n",
    "            \n",
    "        return (X, d), y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"splitted_npy\"\n",
    "list_ids = ds.output_list_ids\n",
    "labels = ds.labels\n",
    "batch_size = 32\n",
    "max_length = ds.window_size\n",
    "n_channels = 1\n",
    "dim = (max_length, n_channels)\n",
    "n_classes = len(pp.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = list(set([id.split(\"_\")[0] for id in list_ids]))\n",
    "random.shuffle(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1 = 0.6\n",
    "sp2 = 0.8\n",
    "train_unique = unique_ids[:int(len(unique_ids)*sp1)]\n",
    "val_unique = unique_ids[int(len(unique_ids)*sp1):int(len(unique_ids)*sp2)]\n",
    "test_unique = unique_ids[int(len(unique_ids)*sp2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [ id for id in list_ids if id.split(\"_\")[0] in train_unique ]\n",
    "val_ids = [ id for id in list_ids if id.split(\"_\")[0] in val_unique ]\n",
    "test_ids = [ id for id in list_ids if id.split(\"_\")[0] in test_unique ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(data_folder, train_ids, demo_df, labels, batch_size, dim, n_classes)\n",
    "validation_generator = DataGenerator(data_folder, val_ids, demo_df, labels, batch_size, dim, n_classes)\n",
    "test_generator = DataGenerator(data_folder, test_ids, demo_df, labels, 1, dim, n_classes, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Reshape, Conv1D, MaxPooling1D, LSTM, Bidirectional, Dense, Activation, Dropout, GaussianNoise, BatchNormalization, Flatten, AveragePooling1D, GlobalAveragePooling1D, Multiply\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, Activation, Dense, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.layers import Add, Reshape, Multiply\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def conv1d_bn(x, filters, kernel_size, padding='same', strides=1, activation='relu'):\n",
    "    x = Conv1D(filters, kernel_size, kernel_initializer='he_normal', padding=padding, strides=strides)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = Activation(activation)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def SE_block(input_tensor, reduction_ratio=16):\n",
    "    ch_input = K.int_shape(input_tensor)[-1]\n",
    "    ch_reduced = ch_input//reduction_ratio\n",
    "    \n",
    "    # Squeeze\n",
    "    x = GlobalAveragePooling1D()(input_tensor) # Eqn.2\n",
    "    \n",
    "    # Excitation\n",
    "    x = Dense(ch_reduced, kernel_initializer='he_normal', activation='relu', use_bias=False)(x)\n",
    "    x = Dense(ch_input, kernel_initializer='he_normal', activation='sigmoid', use_bias=False)(x)\n",
    "    \n",
    "    x = Reshape( (1, ch_input) )(x)\n",
    "    x = Multiply()([input_tensor, x]) # Eqn.4\n",
    "    \n",
    "    return x\n",
    "   \n",
    "def SE_residual_block(input_tensor, filter_sizes, strides=1, reduction_ratio=16):\n",
    "    filter_1, filter_2, filter_3 = filter_sizes\n",
    "    \n",
    "    x = conv1d_bn(input_tensor, filter_1, 1, strides=strides)\n",
    "    x = conv1d_bn(x, filter_2, 3)\n",
    "    x = conv1d_bn(x, filter_3, 1, activation=None)\n",
    "    \n",
    "    x = SE_block(x, reduction_ratio)\n",
    "    \n",
    "    projected_input = conv1d_bn(input_tensor, filter_3, 1, strides=strides, activation=None) if K.int_shape(input_tensor)[-1] != filter_3 else input_tensor\n",
    "    shortcut = Add()([projected_input, x])\n",
    "    shortcut = Activation(activation='relu')(shortcut)\n",
    "    \n",
    "    return shortcut\n",
    " \n",
    "\n",
    "def stage_block(input_tensor, filter_sizes, blocks, reduction_ratio=16, stage=''):\n",
    "    strides = 2 if stage != '2' else 1\n",
    "    \n",
    "    x = SE_residual_block(input_tensor, filter_sizes, strides, reduction_ratio)\n",
    "\n",
    "    for i in range(blocks-1):\n",
    "        x = SE_residual_block(x, filter_sizes, reduction_ratio=reduction_ratio)\n",
    "    \n",
    "    return x\n",
    "    \n",
    "\n",
    "def SE_ResNet50(model_input, demo_input, classes=3):\n",
    "    stage_1 = conv1d_bn(model_input, 64, 7, strides=2, padding='same')\n",
    "    stage_1 = MaxPooling1D(3, strides=2, padding='same')(stage_1)\n",
    "    \n",
    "    stage_2 = stage_block(stage_1, [64, 64, 256], 3, reduction_ratio=16, stage='2')\n",
    "    stage_3 = stage_block(stage_2, [128, 128, 512], 4, reduction_ratio=16, stage='3')\n",
    "    stage_4 = stage_block(stage_3, [256, 256, 1024], 6, reduction_ratio=16, stage='4')\n",
    "    stage_5 = stage_block(stage_4, [512, 512, 2048], 3, reduction_ratio=16, stage='5')\n",
    "\n",
    "    gap = GlobalAveragePooling1D()(stage_5)\n",
    "    \n",
    "    gap_demo = Concatenate()([gap, demo_input])\n",
    "    model_output = Dense(classes, activation='softmax', kernel_initializer='he_normal')(gap_demo)\n",
    "    \n",
    "    model = Model(inputs=(model_input, demo_input), outputs=model_output, name='SE-ResNet50')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "model_input = Input( shape=(4000,1) )\n",
    "demo_input = Input( shape=(9,) )\n",
    "model = SE_ResNet50(model_input, demo_input, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "stopping = tf.keras.callbacks.EarlyStopping(patience=8)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    min_lr=0.001 * 0.001)\n",
    "\n",
    "MAX_EPOCHS = 300\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001, clipnorm=1.)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2670/2670 [==============================] - 365s 130ms/step - loss: 0.5895 - accuracy: 0.7838 - val_loss: 0.6235 - val_accuracy: 0.7666 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "2670/2670 [==============================] - 347s 130ms/step - loss: 0.5317 - accuracy: 0.8059 - val_loss: 0.5553 - val_accuracy: 0.7922 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "2670/2670 [==============================] - 348s 130ms/step - loss: 0.5038 - accuracy: 0.8155 - val_loss: 0.5558 - val_accuracy: 0.7977 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "2670/2670 [==============================] - 349s 131ms/step - loss: 0.4832 - accuracy: 0.8220 - val_loss: 0.5964 - val_accuracy: 0.7977 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "2670/2670 [==============================] - 350s 131ms/step - loss: 0.4342 - accuracy: 0.8398 - val_loss: 0.5841 - val_accuracy: 0.8036 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "2670/2670 [==============================] - 349s 131ms/step - loss: 0.4111 - accuracy: 0.8485 - val_loss: 0.5913 - val_accuracy: 0.7959 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "2670/2670 [==============================] - 348s 130ms/step - loss: 0.3953 - accuracy: 0.8538 - val_loss: 0.5948 - val_accuracy: 0.8017 - lr: 1.0000e-05\n",
      "Epoch 8/300\n",
      "2670/2670 [==============================] - 349s 131ms/step - loss: 0.3918 - accuracy: 0.8550 - val_loss: 0.5981 - val_accuracy: 0.8008 - lr: 1.0000e-05\n",
      "Epoch 9/300\n",
      "2670/2670 [==============================] - 346s 129ms/step - loss: 0.3902 - accuracy: 0.8554 - val_loss: 0.6012 - val_accuracy: 0.8006 - lr: 1.0000e-06\n",
      "Epoch 10/300\n",
      "2670/2670 [==============================] - 348s 130ms/step - loss: 0.3889 - accuracy: 0.8572 - val_loss: 0.5992 - val_accuracy: 0.8011 - lr: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff5e00b50c0>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=MAX_EPOCHS,\n",
    "    callbacks=[reduce_lr, stopping, ],\n",
    "    #workers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28876/28876 [==============================] - 404s 14ms/step\n",
      "[[ 2444    94  2775]\n",
      " [   79    64  1109]\n",
      " [  946   152 21213]]\n",
      "F1: 0.5111505016961123\n",
      "Weighted F1: 0.7974152472615093\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.46      0.56      5313\n",
      "           1       0.21      0.05      0.08      1252\n",
      "           2       0.85      0.95      0.89     22311\n",
      "\n",
      "    accuracy                           0.82     28876\n",
      "   macro avg       0.59      0.49      0.51     28876\n",
      "weighted avg       0.79      0.82      0.80     28876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "probs = model.predict(test_generator)\n",
    "pred = np.argmax(probs, axis=1)\n",
    "labels = [test_generator.labels[i.split(\"_\")[0]] for i in test_generator.list_IDs]\n",
    "print(metrics.confusion_matrix([a for a in labels], [p for p in pred]))\n",
    "print(\"F1:\",metrics.f1_score([a for a in labels], [p for p in pred], average=\"macro\"))\n",
    "print(\"Weighted F1:\",metrics.f1_score([a for a in labels], [p for p in pred], average='weighted'))\n",
    "print(metrics.classification_report([a for a in labels], [p for p in pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "(0, [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2])\n",
      "(0, [2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2])\n",
      "(0, [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2])\n",
      "(0, [2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "(0, [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "(0, [1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0])\n",
      "(0, [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2])\n",
      "(0, [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "(1, [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2])\n",
      "(1, [2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "(0, [2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2])\n",
      "(0, [2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "(0, [2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "(0, [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "(0, [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2])\n",
      "(1, [2, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "(0, [2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0])\n",
      "(0, [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2])\n",
      "(1, [2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "(1, [2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2])\n",
      "(1, [2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 2, 2, 1, 0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 1, 1, 1, 0, 0, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 0, 0, 2, 2])\n",
      "(0, [2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2])\n",
      "(1, [2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "(0, [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2])\n",
      "(0, [0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2])\n",
      "(0, [2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2])\n",
      "(1, [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "test_result = {}\n",
    "for i in range(len(probs)):\n",
    "    if not test_generator.list_IDs[i].split(\"_\")[0] in test_result:\n",
    "        test_result[test_generator.list_IDs[i].split(\"_\")[0]] = []\n",
    "    test_result[test_generator.list_IDs[i].split(\"_\")[0]].append(pred[i])\n",
    "\n",
    "answer = []\n",
    "for i in test_result.keys():\n",
    "    answer.append(test_result[i])\n",
    "labels = [test_generator.labels[i.split(\"_\")[0]] for i in test_result.keys()]\n",
    "\n",
    "for i in zip(labels, answer):\n",
    "    if not i[0] == np.bincount(i[1]).argmax():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 0.559228650137741\n",
      "0.04 0.6859504132231405\n",
      "0.06 0.721763085399449\n",
      "0.08 0.743801652892562\n",
      "0.1 0.7713498622589532\n",
      "0.12000000000000001 0.7520661157024794\n",
      "0.13999999999999999 0.7603305785123967\n",
      "0.16 0.7658402203856749\n",
      "0.18 0.7493112947658402\n",
      "0.19999999999999998 0.7493112947658402\n",
      "0.22 0.7382920110192838\n",
      "0.24 0.7520661157024794\n",
      "0.26 0.7548209366391184\n",
      "0.28 0.7575757575757576\n",
      "0.30000000000000004 0.7575757575757576\n"
     ]
    }
   ],
   "source": [
    "for r in np.arange(0.02, 0.32, 0.02):\n",
    "    test_result = {}\n",
    "    for i in range(len(probs)):\n",
    "        if not test_generator.list_IDs[i].split(\"_\")[0] in test_result:\n",
    "            test_result[test_generator.list_IDs[i].split(\"_\")[0]] = []\n",
    "        test_result[test_generator.list_IDs[i].split(\"_\")[0]].append(pred[i])\n",
    "\n",
    "    answer = []\n",
    "    for i in test_result.keys():\n",
    "        if (np.array(test_result[i]) == 1).sum() / len(test_result[i]) > r:\n",
    "            answer.append(1)\n",
    "        elif (np.array(test_result[i]) == 0).sum() / len(test_result[i]) > r:\n",
    "            answer.append(0)\n",
    "        else:\n",
    "            answer.append(2)\n",
    "    labels = [test_generator.labels[i.split(\"_\")[0]] for i in test_result.keys()]\n",
    "\n",
    "    cf_values = metrics.confusion_matrix([a for a in labels], [p for p in answer]).ravel()\n",
    "    pc_metric = (5*cf_values[0]+3*cf_values[4]+cf_values[8]) /\\\n",
    "    (5*(cf_values[0]+cf_values[1]+cf_values[2])+3*(cf_values[3]+cf_values[4]+cf_values[5])+(cf_values[6]+cf_values[7]+cf_values[8]))\n",
    "    print(r, pc_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 27   2   9]\n",
      " [  0   3   8]\n",
      " [  5   2 133]]\n",
      "F1: 0.6740010946907499\n",
      "Weighted F1: 0.8539404522984162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.71      0.77        38\n",
      "           1       0.43      0.27      0.33        11\n",
      "           2       0.89      0.95      0.92       140\n",
      "\n",
      "    accuracy                           0.86       189\n",
      "   macro avg       0.72      0.64      0.67       189\n",
      "weighted avg       0.85      0.86      0.85       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result = {}\n",
    "for i in range(len(probs)):\n",
    "    if not test_generator.list_IDs[i].split(\"_\")[0] in test_result:\n",
    "        test_result[test_generator.list_IDs[i].split(\"_\")[0]] = []\n",
    "    test_result[test_generator.list_IDs[i].split(\"_\")[0]].append(pred[i])\n",
    "\n",
    "answer = []\n",
    "for i in test_result.keys():\n",
    "    if (np.array(test_result[i]) == 1).sum() / len(test_result[i]) > 0.15:\n",
    "        answer.append(1)\n",
    "    elif (np.array(test_result[i]) == 0).sum() / len(test_result[i]) > 0.15:\n",
    "        answer.append(0)\n",
    "    else:\n",
    "        answer.append(2)\n",
    "labels = [test_generator.labels[i.split(\"_\")[0]] for i in test_result.keys()]\n",
    "\n",
    "print(metrics.confusion_matrix([a for a in labels], [p for p in answer]))\n",
    "print(\"F1:\",metrics.f1_score([a for a in labels], [p for p in answer], average=\"macro\"))\n",
    "print(\"Weighted F1:\",metrics.f1_score([a for a in labels], [p for p in answer], average='weighted'))\n",
    "print(metrics.classification_report([a for a in labels], [p for p in answer]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7630853994490359\n"
     ]
    }
   ],
   "source": [
    "cf_values = metrics.confusion_matrix([a for a in labels], [p for p in answer]).ravel()\n",
    "pc_metric = (5*cf_values[0]+3*cf_values[4]+cf_values[8]) /\\\n",
    "(5*(cf_values[0]+cf_values[1]+cf_values[2])+3*(cf_values[3]+cf_values[4]+cf_values[5])+(cf_values[6]+cf_values[7]+cf_values[8]))\n",
    "print(pc_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joon",
   "language": "python",
   "name": "joon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
